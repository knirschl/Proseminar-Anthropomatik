\section{Funktionsweise}
\label{funktion}

Dieser Abschnitt erklärt die Arbeitsweise der Inversionsmethode im Allgemeinen. 
Danach wird kurz das Prinzip der Hashtabelle wiederholt, um danach die 
Funktionsweise der Hash-basierten Inversionsmethode zu erläutern.

% SVG
% \begin{figure}[!h]
%     \centering
%     \def\svgwidth{\columnwidth}
%     % inkscape -D image.svg  -o image.pdf --export-latex
%     \scalebox{1}{\input{../../Media/pdf_tex/examplePlot2.pdf_tex}}
%     \caption{(a) 500 Punkte mit einer logistischen Dichte auf der X- und Y-Achse 
% (b) 500 Punkte standardnormalverteilt \eqref{eq:stdnormdensity}.}
%     \label{bild:examplePlot}
% \end{figure}
\begin{figure*}%[htb!]
    \centering
    \begin{subfigure}[b]{.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pdf_plots/idf2_log-sin_iu500c-RND.pdf}
        \caption{Eingabewerte zufällig generiert mit \code{random}}
        \label{fig:logsin_random}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pdf_plots/idf2_log-sin_iu500c-GRS.pdf}
        \caption{Eingabewerte aus einer Goldenen Schnitt Sequenz}
        \label{fig:logsin_uniform}
    \end{subfigure}
    \caption{$500$ Punkte mit einer logistischen Dichte auf der X- und einer sinusoiden auf der Y-Achse}
    \label{fig:rand_vs_uniform}
\end{figure*}


\subsection{Inversionsmethode}
\begin{table}%[htb!]
    \centering
    \begin{tabular}{lll}
    Name         & Funktion & Zufällige Variable \\
                 &          &                    \\
    Exponentiell & $1 - e^{-x}$ & $\log(1/U)$ \\
    Logistisch   & $1 / (1 + e^{-x})$ & $-\log(\dfrac{1-U}{U})$ \\
    Cauchy       & $1/2 + (1/\pi) \arctan(x)$ & $\tan(\pi U)$
    \end{tabular}
    \caption{Explizit invertierbare Verteilungsfunktionen \cite{devroye-non_uniform_random_variate-1986}}
    \label{tab:invFuncs}
\end{table}

Devroye \cite{devroye-non_uniform_random_variate-1986} beschreibt in seinem Buch 
die Inversionsmethode als eine Methode, bei der mithilfe des Inversen $F^{-1}$ 
einer bekannten Verteilungsfunktion $F$ und mit einer uniformen, zufälligen Zahl 
$U \in [0, 1]$ eine zufällige Zahl $X = F^{-1}(U)$ generiert wird. Für schnell 
berechenbare und bekannte Inverse, zu denen die Funktionen in Tabelle 
\ref{tab:invFuncs} gehören, ist diese Methode sehr einfach umzusetzen. Dadurch, 
dass die erzeugten Zahlen aus fortlaufenden Zufallszahlen entstehen, gibt es eine 
monotone Beziehung zwischen $U$ und $X$. Das führt dazu, dass ein Paar 
$(x_1, x_2)$, bei dem $X_1$ und $X_2$ maximal anti-korreliert zueinander sind, mit 
\begin{equation}
    (F^{-1}(U),\, F^{-1}(1 - U))
\end{equation}
berechnet werden kann. Diese Eigenschaft wird vor allem in Simulationen benötigt.

Da im Folgenden nur noch von gleichmäßig verteilten Ausgangswerten gesprochen 
wird, wird kurz erklärt, warum sich diese Ausarbeitung nur darauf beschränkt. In 
Abbildung \ref{fig:rand_vs_uniform} sind zwei Abbildungen zu sehen. Beide 
Abbildungen bilden $500$ Punkte $y \in [0, 1]$ auf $500$ andere Punkte ab. Dabei 
wird der X-Achsenanteil der Punkte mithilfe einer logarithmischen Funktion, siehe 
\ref{tab:invFuncs}, und der Y-Achsenanteil mit einer Sinusfunktion verformt. In 
\ref{fig:logsin_random} sind die gewählten Ausgangswerten mit der \code{uniform}-
Funktion des Pythonpaketes \textit{random} zufällig generiert worden. Zum einen 
lässt sich dadurch die Funktion nicht genauso gut erkennen, wie mit nicht-zufälligen 
Punkten. Zum anderen entstehen dadurch die für computergenerierte, naive 
Zufallsfunktionen typischen Ketten an Punkten und Stellen mit höherer Dichte, 
sowie leere Flecken. Wie in der Einleitung beschrieben, benötigen 
Simulationsalgorithmen aber eine homogene Verteilung, um genauer simulieren zu können. 
Um dies zu erreichen, kann, wie schon erwähnt, eine Goldene-Schnitt-Sequenz verwendet 
werden. Die selbe Funktion wie aus \ref{fig:logsin_random} ist auch in \ref{fig:logsin_uniform} 
verwendet worden, allerdings wurde eine Goldene-Schnitt-Sequenz verwendet. Diese 
Sequenz beschreibt auch zufällig verteilte Zahlen, allerdings werden die Punkte 
durch die Berechnungsvorschrift gleichmäßig verteilt. Dies hat auch sichtbare Auswirkkungen 
auf die Verformung, da auch nach der Verformung die Punkte noch gleichmäßig verteilt 
sind und keine Cluster entstehen. Offensichtlich kann ein Algorithmus diese Daten 
besser für Schätzberechnungen verwenden, als zufällig verteilte Daten.

Durch die Erzeugung der Zufallsvariable $X$ durch das Inverse einer 
Verteilungsfunktion kann die Inversionsmethode allerdings nur dann optimal 
angewandt werden, wenn $F^{-1}$ einfach zu berechnen ist oder sogar schon bekannt 
ist. Durch heutige numerische Algorithmen können aber auch Funktionen, welche 
nicht \glqq per Hand\grqq{} invertierbar sind, in der vorgestellten Weise benutzt 
werden. 

Nach Devroye können, nur unter Verwendung sogenannter \glqq einfachen 
Transformationen\grqq, Paare von unabhängigen Variablen generiert werden. Zum 
Beispiel kann mit der Standardnormalverteilung $\dfrac{e^{-x^2/2}}{\sqrt{2\pi}}$ 
ein Paar von unabhängigen, zufälligen standardnormalverteilten Variablen mit 
\begin{equation}
    (X, Y) = \bigg( \sqrt{\log(\dfrac{1}{U_1})}\cos(2\pi U_2),\, \sqrt{\log(
        \dfrac{1}{U_1})}\sin(2\pi U_2) \bigg)
    \label{eq:stdnormdensity}
\end{equation}
generiert werden. Dabei sind $U_1, U_2 \in [0, 1]$ unabhängige gleichverteile 
zufällige Variablen.

Bei einem Zufallsvektor $ (X_1, ..., X_n) \in \mathbb{R}^n$ wird die 
Inversionsmethode auf je eine Dimension angewandt, wobei die Zufallszahl dieser 
Dimension generiert wird und dann rekursiv die nachfolgenden Dimensionen 
berechnet werden. Genauer bedeutet das, dass zuerst die Variable $X_n$ der 
höchsten Dimension berechnet wird. Danach wird $X_{n-1}$ mit der zugewiesenen 
Funktion berechnet, wobei $X_n$ als bedingte Verteilung mit eingerechnet wird.


\subsection{Hashtabelle}
Eine Hashtabelle ist eine Datenstruktur, die mithilfe einer Hashfunktion 
$H: V \rightarrow K$ einen Wert $v \in V$ auf den zugehörigen Schlüssel $k \in K$ 
abbildet. Die Werte werden dann in einem Array gespeichert, wobei der Schlüssel 
die Position angibt. Da es in der Praxis meistens mehr Werte als Stellen im Array 
gibt, treten allerdings Kollisionen auf. Diese können entweder dadurch gelöst 
werden, dass das Array pro Schlüssel eine verkettete Liste enthält. In diese 
werden dann die kollidierende Werte hintereinander geschrieben. Die zweite 
verbreitete Möglichkeit ist lineares Sondieren. Dabei wird der Wert immer an die 
nächste freie Stelle in der Hashtabelle, von seinem eigentlichem Platz aus 
gesehen, geschrieben.


\subsection{Inversion mit Hashing}
\label{funktion_invhashing}
Bei komplizierteren Inversen ist die normale Inversionsmethode nicht 
mehr effizient anwendbar. Um sie beschleunigen zu können wurden deshalb mehrere 
Möglichkeiten entwickelt. Eine davon ist es, eine Hashtabelle in der von Chen und 
Asau \cite{chen_asau-generating_random_variates-1974} erarbeiteten Vorgehensweise 
verwendet wird. Um diese Methode zu verwenden, wird für $j \in [1, n]$ die 
Wahrscheinlichkeit $p_j$ als $p_j = \mathbb{P}(X=v_j)$ definiert. Mithilfe einer uniformen 
Variablen $U \in [0, 1]$ wird die Zufallsvariable $X$ durch 
\begin{equation}
    F(v_{j-1}) < U \leq F(v_j)
    \label{eq:hash_ineq}
\end{equation}
berechnet, wobei $X = v_j$ ist. Diese Ungleichheit kann zwar ohne großen Aufwand 
berechnet werden, doch bei sehr großem $n$ läuft jede einzelne Generierung trivial 
in $O(n)$. Mit dem Einsatz einer Hashtabelle, die wie eine Indextabelle agiert, 
wird für jede Generierung nur approximiert $O(1)$ Zeit benötigt. Dafür wird aus 
den Werten $F(v_j)$ der Wert
\begin{equation}
     I_j = \lfloor F(v_j) * d \rfloor + 1
     \label{eq:hash_I}
\end{equation}
berechnet. Dabei sollte $d = 10^m$ so gewählt werden, dass $\min\limits_{0\le 
j\le n}(I_j) = 1$ ist. Danach wird die Indextabelle $T(k),\, k \in [1,\, \max
\limits_{0\le j\le n}(I_j)]$ initialisiert. Dafür werden die $I_j$ als Indexliste 
verwendet. Für jedes $I_j$ wird $T(I_j)$ als das $k$ gesetzt, für das $I(k) = 
I(j)$ ist. Falls ein Element $I_k$ nicht in der Indexliste vorhanden ist, gilt 
$T(I_k) = T(I_{k+1})$. 

Nach diesen Vorberechnungen und Initialisierungen kann die Hashtabelle verwendet 
werden, um eine Zufallszahl $X$ zu berechnen. Dafür wird aus einer uniformen 
zufälligen Zahl $U$ das zugehörige $I_U$ \eqref{eq:hash_I} und $i = T(I_U)$ berechnet. $i$ 
beschränkt damit die Teilmengen $F(v_j)$, die \eqref{eq:hash_ineq} erfüllen 
können. Die zu überprüfenden Teilmengen sind gegeben durch die Menge $\{F(v_i),\, \dots,
\, F(v_{r-1})\}$, wobei $r$ die nächstgrößere Zahl ist, für die $I(i) \neq I(r)$ 
gilt. Für den Fall, dass $U > F(v_{r-1})$ ist, gilt bei Einsatz der Hashtabelle 
$T$ immer $U \leq F(v_r)$, da ansonsten nicht $i = T(I_U)$ gelten würde. Nachdem 
ein $v_j$ gefunden wurde, für das \eqref{eq:hash_ineq} erfüllt ist, wird $X$ auf 
$v_j$ gesetzt.

12 Jahre nach Chen und Asau's Ansatz wird in Devroye 
\cite{devroye-non_uniform_random_variate-1986} eine abgewandelte Methode 
vorgestellt. Dabei wird eine Hashtabelle der Größe $N$ erstellt, wobei $N$ die 
Anzahl der möglichen Werte angibt. An der $i$-ten Stelle in der Hashtabelle wird 
der Wert von $X$ mit $\mathbb{P}(X) = p_X$ gespeichert, falls $U = \dfrac{i}{N},\; i \in 
[0,\, N)$ wäre. Nach dieser Initialiserung wird der Startindex $Z$, ab welchem 
eine Lösung zu finden ist, mit $Z = \lfloor N * U \rfloor$ berechnet. Falls man 
nun eine kummulative Verteilung vorliegen hat, oder eine Tabelle mit Partialsummen 
erstellt hat, kann jetzt mit minimalem Aufwand ab der $Z$-ten Partialsumme eine 
Lösung der bekannten Formel \eqref{eq:hash_ineq} von Chen und Asau gesucht werden.
